\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[parfill]{parskip}
\let\oldemptyset\emptyset
\let\emptyset\varnothing


\title{\textbf{Esssentials of Applied Data Analysis\\
				IPSA-USP Summer School 2018}\newline\\
				The Basics of Probability Theory - Independence and conditional probability}

\author{Leonardo Sangali Barone\\ \href{leonardo.barone@usp.br}{leonardo.barone@usp.br}}
\date{jan/18}

\begin{document}

\maketitle

\section*{Introduction to Probability - Part III}

	Basic Notions of probability, part III.

	\subsection*{Independence}
	The event $B$ is said to be independent of the event $A$ if the probability that $B$ occurs is not influenced by whether $A$ has or has not ocurred.\\

	IMPORTANT: Independence is a \emph{key} concept to us	

	\subsection*{Independence - Examples}
	\begin{itemize}
		\item Toss a coin twice. The result of the second toss is independent of the result in the first toss. 
		\item Take one card from a deck. Don't put it back. Take a second card. The result of the second card is \emph{not} independent of the first.
		\item In general, a legislator support to a government (or being a woman, or being from some part of the country) is not independent of her party.		
	\end{itemize}	


	\subsection*{Axioms and theorems of probability (5)}
	\begin{itemize}
		\item If A and B are independent events, then $P(A \cap B) = P(A) * P(B)$
	\end{itemize}


	\subsection*{Independence - Coin}
	1) Toss a coin twice.
	What's is the probability of getting heads ($H$) twice?
	\[P(H_1\cap H_2) = P(H_1) * P(H_2) = P(H) * P(H) =\frac{1}{2} * \frac{1}{2} = \frac{1}{4}\]
	\[\text{Sample Space = \{H,H\},\{H,T\},\{T,H\},\{T,T\}}\]
	
	2) Toss a coin 50 times. What's is the probability of getting 50 times head ($H$)?
	\[P(H_1\cap H_2 \cap...\cap H_{50}) = (P(H))^{50} = \left(\frac{1}{2}\right)^{50} \simeq 8.8 * 10^{-16}\]
	
	3) Toss a coin 10 times. What's is the probability of  getting at least one Tail ($T$)?
	\[P(\text{1 Tail or more}) = P(\text{exactly 1 Tail}) + P(\text{exactly 2 Tails}) + ... + P(\text{exactly 10 Tails}) =\]
	\[= \{P(T\cap H \cap ... \cap H) + P(H \cap T\cap H \cap ... \cap H) + P(H \cap ... \cap H \cap T)\} +  \]
	\[+P(\text{exactly 2 Tails}) + ... + P(\text{exactly 10 Tails}) =\]

	OMG!!! How do I compute that?\\

	Use the fact that the complementary of ``getting at least one Tail'' is ``not getting any Tails'', which is the same as ``getting 10 heads''. And ``getting 10 heads'' is much easier to compute:
	\[P(\text{1 Tail or more}) = 1 - P(\text{not getting any Tails}) = 1 - P(\text{10 Hs}) = 1 - (1/2)^{10}  \simeq 0.9990234\]


	\subsection*{Independence - Cards}
	
	Take a card from a deck (52 cards).\\
	
	What's is the probability of getting a Queen ($Q$)?
	\[P(Q) = \frac{4}{52} = \frac{1}{13}\]
	
	What's is the probability of getting a Hearts ($H$)?
	\[P(Q) = \frac{13}{52} = \frac{1}{4}\]\
	
	
	What's is the probability of getting the Queen of Hearts ($Q \cap H$)?
	\[P(Q \cap H) = P(Q) * P(H) = \frac{1}{13} * \frac{1}{4} = \frac{1}{52}\]

	If the card deck is complete, the suit and the number are independent of each other, so we can apply $P(A \cap B) = P(A) * P(B)$

	\subsection*{Conditional Probability}
	
	Let $A$ be an event that is \textbf{not independent} of $B$, and $P(B)>0$. The probability that an event A occurs once B has ocurred -- $P(A|B)$, which can be read as \emph{conditional probability} of A given B -- is \textbf{not} equal to the probabilty of A:
	
	\[P(A|B) \neq P(A)\]
	
	\subsection*{Axioms and theorems of probability (6)}
	\begin{itemize}
		\item If A and B are not independent events, then the conditional probability of A given B, $P(A|B)$, is defined as
	\[P(A|B) = \frac{P(A\cap B)}{P(B)}\]
 
	\end{itemize}

	\subsection*{Conditional Probability}
	Intuitively, we can think as the conditional probability of A given B as:

		\[P(A|B) = \frac{
						\frac{
							\text{\# of outcomes in A \textbf{and} B}
							}
							{\text{\# of outcomes in the sample space}
							}
						}
						{
						\frac{
							\text{\# of outcomes in B}
							}
							{\text{\# of outcomes in the sample space}
							}
						}
		=\frac{\text{\# outcomes in event A \textbf{and} B}}
							{\text{\# outcomes in B}
							}\]



	\subsection*{Conditional Probability - dice}
	
	Roll a dice. Define event $B$ as "gettting a number less than or equal to 3". What is the probability of getting a 1 (event $A$) given that $B$ occurred?\\
	 
	Answer:

	\[P(A|B) = \frac{P(A\cap B)}{P(B)} = 
	\frac{
						\frac{
							\text{\# of outcomes in A \textbf{and} B}
							}
							{\text{\# of outcomes in the sample space}
							}
						}
						{
						\frac{
							\text{\# of outcomes in B}
							}
							{\text{\# of outcomes in the sample space}
							}
						} =
						\frac
							{\frac{\#\{1\}}{\#\{1,2,3,4,5,6\}}}
							{\frac{\#\{1,2,3\}}{\#\{1,2,3,4,5,6\}}} = 
							\frac{\frac{1}{6}}{\frac{1}{2}} = \frac{2}{6} = \frac{1}{3}\]
	
	Alternatively, 	you can read this problem as ``I already know I got 1, 2 or 3. Given that, what is the probability that I got a 1''?

	
	\[P(A|B) = \frac{P(A\cap B)}{P(B)} = 		=\frac{\text{\# outcomes in event A \textbf{and} B}}
							{\text{\# outcomes in B}
							} = 
							\frac{\#\{1\}}{\#\{1,2,3\}}= 
							\frac{1}{3}\] 	 


	\subsection*{Conditional Probability - family - answers}
	1) A family has two kids. What is the probability that both kids be are girls?

	\[P(G \cap G) = \left(\frac{1}{2}\right)^2 = \frac{1}{4} \text{ (Independent events)}\]
	
	2)A family has two kids. The first is a girl. What is the probability that the other one is also a girl?\\

	\[P(G_2) = \frac{1}{2}\text{ (Independent events)}\]

	3) A family has two kids. One is a girl (event $B$). What is the probability that the other kid is a girl (event $A$ = 2 girls)?\\
	
	Let's look at the sample space: \{(B,B), (B,G), (G,B) and (G,G)\} form the complete sample space. The conditionality is that one of the kids is a girl and the combination (B,B) is no longer possible. Hence, our ``new'' sample space is: \{(B,G), (G,B) and (G,G)\}. So we have
	
	\[P(A|B) = \frac{P(G\cap G)}{P(G)} = \frac{\frac{\#\{(G,G)\}}{\#\{(B,B), (B,G), (G,B), (G,G)\}}}
							{\frac{\#\{(B,G), (G,B), (G,G)\}}{\#\{(B,B), (B,G), (G,B), (G,G)\}}} = 
							\frac{\frac{1}{4}}{\frac{3}{4}} = \frac{1}{3} \]

	Or, more simply, 
	
	\[P(A|B) = \frac{P(G\cap G)}{P(G)} = \frac{\#\{(G,G)\}}{\#\{(B,G), (G,B), (G,G)\}} = \frac{1}{3}\]

	4) (SUPER HARD EXTRA QUESTION) A family has two kids. One is \textbf{a girl called Arya} (event $B$). What is the probability that the other kid is a girl (event $A$ = 2 girls)?\\

	Answer can be found at Imai's or Mlodinov's books.

	\subsection*{Axioms and theorems of probability (7)}
	\begin{itemize}
		\item If A and B are independent events, then $P(A|B) = P(A)$ and the formula
	\[P(A|B) = \frac{P(A\cap B)}{P(B)}\]
	can be rewritten as (as previously seen)
	\[P(A\cap B) = P(A)*P(B)\]
			\item If A and B are mutually exclusive, then
		\[P(A\cap B) = 0\]
			hence
		 \[P(A|B) = P(B|A) = 0\] 
	\end{itemize}


	\subsection*{It's all about conditionality}

 	Conditionality is central to statistics. Let's consider some well know social sciences problems.

	\begin{itemize}
		\item	Race/Gender wage gap: we are often interested in measuring gender and/or race wage gap \emph{given} other individual characteristics (e.g. - education, family enviroment, etc).
		\item Likelihood of voting for the incumbent \emph{given} economy performance (GDP, unempolyment, etc)
		\item Probability of finshing high school \emph{given} income.
		\end{itemize}

Hey, let's discuss it for a few minutes.


\end{document}